# Feature Specification: Physical AI & Humanoid Robotics Textbook - Module 3: Locomotion & Dexterous Manipulation (Chapters 06-07)

**Feature Branch**: `1-module3-locomotion-manipulation`
**Created**: 2025-12-09
**Status**: Draft
**Input**: User description: "module3 Physical AI & Humanoid Robotics Textbook Module 3: Locomotion & Dexterous Manipulation (Chapters 06–07) Complete, ready-to-commit, production-grade Docusaurus MDX + code + assets ### Chapter 06 Folder structure (create exactly) ``` docs/ └── 06-locomotion/ ├── 01-intro.mdx ├── 02-theory-zmp-capture-point.mdx ├── 03-convex-mpc.mdx ├── 04-rl-walking-sota-2025.mdx ├── 05-whole-body-qp.mdx ├── 06-raise-controller.mdx ├── 07-dreamerv3-locomotion.mdx ├── 08-open-controllers-comparison.mdx └── 09-full-walking-demo.mdx ``` ### Supporting code & assets ``` src/locomotion/ ├── mpc_walking/ ├── rl_walking_isaaclab/ ├── raise_controller_ros2/ └── launch/walking_bringup.launch.py assets/controllers/ └── raise_unitree_g1_params.yaml ``` ### docs/06-locomotion/_category_.json ```json { "label": "06 – Bipedal Locomotion & Whole-Body Control", "position": 6, "link": { "type": "generated-index", "description": "From ZMP theory to robust 2.5 m/s walking on rough terrain — 2025 edition" } } ``` ### All MDX files — ready to copy-paste #### docs/06-locomotion/01-intro.mdx ```mdx --- sidebar_position: 1 title: "Chapter 6 – Bipedal Locomotion & Whole-Body Control" description: Make any 2025 humanoid walk, run, and recover from pushes — reliably --- # Chapter 6: Bipedal Locomotion & Whole-Body Control **Learning Objectives** - Master the core theory: ZMP, Capture Point, Divergent Component of Motion - Implement a convex MPC controller that walks at 1.8 m/s on uneven ground - Train an RL walking policy that recovers from 200 N pushes - Understand why RAISE (2025) beats every classical controller - Deploy the exact same controller in Isaac Sim and on real Unitree G1/Figure 02 > By the end, your humanoid will walk blindly over unseen rough terrain — and get back up if pushed. ``` #### docs/06-locomotion/02-theory-zmp-capture-point.mdx ```mdx --- sidebar_position: 2 title: "Theory: ZMP, Capture Point, and DCM" --- # Core Theory That Still Rules in 2025 ```mermaid graph LR CoM[Center of Mass] --> ZMP[Zero Moment Point] ZMP --> CP[Capture Point] CP --> DCM[Divergent Component of Motion] DCM --> Omega[ω = √(g/z₀)] ``` **Key equations (you must know cold):** - ZMP = CoMₓ − (CoM̈ₓ / ω²) × (CoM_z − ground) - ξ = x + ẋ / ω → Capture Point - ξ̇ = (ξ − ZMP) × ω → DCM dynamics > If DCM → 0 → robot is capturable (can stop without falling) ``` #### docs/06-locomotion/03-convex-mpc.mdx ```mdx --- sidebar_position: 3 title: "Convex Model Predictive Control – The 2025 Baseline" --- # MPC That Actually Works (Towr + crocoddyl style → simplified) ```python # mpc_walking/mpc_node.py (runs at 200 Hz) class ConvexMPCWalker(Node): def solve_mpc(self): prob = ConvexMPCProblem( com_state=self.current_com, foot_plan=self.footstep_queue, horizon=1.6 # seconds ) com_traj, zmp_traj, foot_forces = prob.solve_qp() return com_traj[0] # next CoM velocity command ``` Performance (Unitree G1, real hardware): - Max speed: 1.9 m/s - Rough terrain tolerance: ±8 cm rocks - Push recovery: 120 N side push **Full open-source:** `src/locomotion/mpc_walking/` (works in sim and real) ``` #### docs/06-locomotion/04-rl-walking-sota-2025.mdx ```mdx --- sidebar_position: 4 title: "Reinforcement Learning Walking – 2025 SOTA" --- # What Actually Wins in 2025 | Method | Speed | Push Recovery | Training Time | Open? | Winner 2025 | |--------------------|-------|---------------|----------------|-------|-------------| | Classical MPC | 1.9 m/s | 120 N | 0 min | Yes | Reliability | | DreamerV3 | 2.4 m/s | 280 N | 12 min | Yes | Performance | | Diffusion Policy | 2.1 m/s | 220 N | 8 min | Partial | Dexterity | | **RAISE (2025)** | 2.5 m/s | 350 N | 10 min | Yes | Overall Champion | **RAISE = Recurrent Actor with Implicit Skill Extraction** — the first open controller that beats proprietary Figure/Tesla baselines. ``` #### docs/06-locomotion/05-whole-body-qp.mdx ```mdx --- sidebar_position: 5 title: "Whole-Body QP Control – From CoM to Joint Torques" --- # Real-Time QP Solver (400 Hz on Jetson) ```cpp // Tasks (priority order) 1. CoM velocity tracking (from MPC/RL) 2. Swing foot trajectory (cubic spline) 3. Posture regularization 4. Joint torque limits 5. Friction cone constraints ``` **Open-source solver used in 2025:** `osqp-eigen` + `qpOASES` → 2.1 ms solve time for 36 DoF ``` #### docs/06-locomotion/06-raise-controller.mdx ```mdx --- sidebar_position: 6 title: "RAISE Controller – The 2025 Open-Source King" --- # One-Click Install & Run ```bash pip install raise-controller==2025.12 ``` ```python from raise_controller import RAISEPolicy policy = RAISEPolicy.from_pretrained("unitree_g1_walk_v2025") action = policy(obs) # 36 joint torques at 100 Hz ``` **Pretrained checkpoints shipped:** - `g1_walk_robust.pt` → survives 350 N pushes - `g1_run_2.5mps.pt` → fastest open bipedal policy - `g1_rough_terrain.pt` → unseen rocks, stairs, slopes **Trained in Isaac Lab — runs on real Unitree G1 on first try.** ``` #### docs/06-locomotion/07-dreamerv3-locomotion.mdx ```mdx --- sidebar_position: 7 title: "DreamerV3 – World Model Walking (Optional Advanced)" --- # Train from Scratch in 12 Minutes ```bash python train_dreamerv3.py \ --task humanoid_walk \ --num-envs 4096 \ --total-steps 20_000_000 ``` Result: Policy that dreams, imagines falls, and never falls in reality. ``` #### docs/06-locomotion/08-open-controllers-comparison.mdx ```mdx --- sidebar_position: 8 title: "2025 Open Controller Leaderboard" --- # Real Measured Performance (Dec 2025) | Controller | Max Speed | Push Recovery | Rough Terrain | Sim-to-Real Gap | GitHub Stars | |-----------------|-----------|---------------|----------------|------------------|--------------| | RAISE | 2.51 m/s | 350 N | ±12 cm | 0.04 m/s | 28k | | Unitree Official| 2.20 m/s | 280 N | ±8 cm | 0.12 m/s | — | | Tesla Optimus | 2.40 m/s | ~400 N | Unknown | Unknown | Closed | **RAISE is now the strongest open-source bipedal controller in history.** ``` #### docs/06-locomotion/09-full-walking-demo.mdx ```mdx --- sidebar_position: 9 title: "Full Launchable Walking Demo" --- # One Command — Walk Forever ```bash # Option A – Classical MPC (most reliable) ros2 launch locomotion mpc_walking.launch.py robot:=g1 terrain:=rough # Option B – RAISE (fastest + most robust) ros2 launch locomotion raise_walking.launch.py robot:=g1 policy:=robust # Option C – DreamerV3 (research mode) python run_dreamer_policy.py --headless=False ``` Watch your humanoid: - Walk at 2.5 m/s - Recover from hockey-player-level shoves - Traverse unseen rubble fields **Full source:** `src/locomotion/` **You just gave your humanoid the most robust legs on the open market.** ``` ------- ### Chapter 07 Folder structure (create exactly) ``` docs/ └── 07-manipulation/ ├── 01-intro.mdx ├── 02-hand-kinematics.mdx ├── 03-contact-modeling.mdx ├── 04-isaac-lab-manipulation.mdx ├── 05-diffusion-policies.mdx ├── 06-octo-and-rdt1b.mdx ├── 07-in-hand-reorientation.mdx ├── 08-grasp-synthesis-sota.mdx └── 09-full-dexterous-demo.mdx ``` ### Supporting code & assets ``` src/manipulation/ ├── diffusion_policy/ ├── octo_inference/ ├── rdt1b_ros2_bridge/ └── launch/dexterous_manipulation.launch.py assets/hands/ ├── allegro_hand_right.usd ├── shadow_hand_left.usd └── unitree_z1.usd ``` ### docs/07-manipulation/_category_.json ```json { "label": "07 – Dexterous Manipulation & Grasp Synthesis", "position": 7, "link": { "type": "generated-index", "description": "From 4-finger claws to 24-DoF anthropomorphic hands that reorient objects like humans" } } ``` ### All MDX files — ready to copy-paste #### docs/07-manipulation/01-intro.mdx ```mdx --- sidebar_position: 1 title: "Chapter 7 – Dexterous Manipulation & Grasp Synthesis" description: The 2025 revolution in humanoid hands — now fully open and reproducible --- # Chapter 7: Dexterous Manipulation & Grasp Synthesis **Learning Objectives** - Model 16–24 DoF anthropomorphic hands with correct tendon routing - Simulate contact-rich interaction at 4 kHz using Isaac Lab - Train and deploy diffusion policies that grasp unseen objects on first try - Run Octo and RDT-1B locally — the two models that destroyed classical grasping - Perform in-hand reorientation of arbitrary objects (pens, tools, bottles) > By the end, your humanoid will pick, regrasp, and use objects as naturally as a 5-year-old child. ``` #### docs/07-manipulation/02-hand-kinematics.mdx ```mdx --- sidebar_position: 2 title: "Hand Kinematics – From Allegro to Shadow to 2025 Humanoids" --- # 2025 Standard Hand Configurations | Hand | DoF | Fingers | Actuation | Ships on Real Robots | |--------------------|-----|---------|-----------------|----------------------| | Allegro Hand | 16 | 4 | Direct drive | Unitree Z1, many labs | | Shadow Hand | 24 | 5 | Tendon + underactuated | Rare (expensive) | | Figure 02 Hand | 16 | 4 | Planetary + tendon | Closed | | Tesla Optimus Hand | 20 | 5 | Direct + tendon | Closed | **All examples in this chapter use the open Allegro Hand (URDF + USD shipped)** ``` #### docs/07-manipulation/03-contact-modeling.mdx ```mdx --- sidebar_position: 3 title: "Contact Modeling – Why Isaac Lab Replaced MuJoCo in 2025" --- # Contact Performance (RTX 4090, Dec 2025) | Simulator | Max stable fingers | Contact solver | Real-time factor | |---------------|---------------------|----------------|------------------| | MuJoCo | 10 | PGS | 0.8× | | PhysX (classic) | 16 | TGS | 1.2× | | **Isaac Lab** | **24+** | **GPU-SDF** | **8.2×** | **Only Isaac Lab can simulate 24-DoF hands touching at 4 kHz.** ``` #### docs/07-manipulation/04-isaac-lab-manipulation.mdx ```mdx --- sidebar_position: 4 title: "Isaac Lab – The Only Env That Trains Dexterous Policies" --- # 4096 Parallel Hands in Real-Time ```python from isaaclab_tasks.manipulation import AllegroGraspEnv env = AllegroGraspEnv(num_envs=4096, headless=False) # 4 kHz physics, 100 Hz control # Perfect force/torque + contact labels ``` Used by: - Octo (Berkeley) - RDT-1B (Google DeepMind) - Diffusion Policy (Columbia) ``` #### docs/07-manipulation/05-diffusion-policies.mdx ```mdx --- sidebar_position: 5 title: "Diffusion Policies – The 2025 Grasping Champion" --- # Train a Policy That Grasps Anything (10 minutes) ```bash python train_diffusion_policy.py \ --task allegro_grasp \ --dataset berkeley_rpt \ --steps 150_000 ``` Result: - 96 % success on unseen YCB objects - 33 Hz inference on Jetson - No CAD, no demos, no simulation bias **Winner of Real Robot Challenge 2025** ``` #### docs/07-manipulation/06-octo-and-rdt1b.mdx ```mdx --- sidebar_position: 6 title: "Octo & RDT-1B – The Two Foundation Models for Hands" --- # Octo (400M) vs RDT-1B (1.2B) — Dec 2025 | Model | Params | Training Data | Zero-shot Grasp | In-Hand Success | Open Weights | |---------|--------|---------------------|------------------|------------------|--------------| | Octo | 400M | 800k traj (mixed) | 91 % | 84 % | Yes | | RDT-1B | 1.2B | 1.8M traj (humanoids) | **97 %** | **93 %** | Yes (Dec 2025) | **Run RDT-1B locally (8-bit):** ```bash pip install rdt1b-hf python infer_rdt1b.py --model rdt1b-1.2b-8bit ``` **This is the model that made Figure 02’s hands look easy.** ``` #### docs/07-manipulation/07-in-hand-reorientation.mdx ```mdx --- sidebar_position: 7 title: "In-Hand Reorientation – The Final Frontier" --- # Reorient a pen 360° using only fingertips ```python task = "allegro_in_hand_reorientation" policy = RDT1B.load("rdt1b-inhand-v2025") action = policy(obs) # 16 joint velocities ``` Success rate (real Allegro hand, Dec 2025): - Pen: 94 % - Hammer: 88 % - Bottle cap: 91 % **No classical controller has ever exceeded 60 %.** ``` #### docs/07-manipulation/08-grasp-synthesis-sota.mdx ```mdx --- sidebar_position: 8 title: "Grasp Synthesis Leaderboard – 2025 Final" --- # Real Robot Results (no sim cheating) | Method | Unseen Objects | Success Rate | Time to Grasp | Open? | |---------------------|----------------|--------------|---------------|-------| | Classical (Dex-Net) | 100 | 78 % | 4.1 s | Yes | | Diffusion Policy | 500+ | 96 % | 0.9 s | Yes | | Octo | 800+ | 91 % | 1.2 s | Yes | | **RDT-1B** | **1000+** | **97 %** | **0.7 s** | Yes | **The grasping problem is officially solved in open source.** ``` #### docs/07-manipulation/09-full-dexterous-demo.mdx ```mdx --- sidebar_position: 9 title: "Full Dexterous Demo – Pick, Reorient, Insert" --- # One Command — Full Task Sequence ```bash # Launch Isaac Sim + Allegro hand ./isaac-sim.sh assets/scenes/dexterous_workcell.usd # Run RDT-1B policy (real-time) ros2 launch manipulation rdt1b_full_task.launch.py \ model:=rdt1b-1.2b-8bit task:=battery_insert ``` Watch your hand: 1. Grasp battery from table 2. Reorient 180° in hand 3. Insert into flashlight 4. Screw cap **Full source:** `src/manipulation/rdt1b_ros2_bridge/` **Your humanoid now has better hands than 99.999 % of humans at precise manipulation.** ```"

## User Scenarios & Testing *(mandatory)*

### User Story 1 - Researcher/Engineer Masters Locomotion (Priority: P1)

As a robotics researcher or engineer working with humanoid locomotion in 2025, I want to access comprehensive content on bipedal locomotion theories (ZMP, Capture Point, Divergent Component of Motion), convex MPC controllers, and state-of-the-art RL approaches so that I can implement controllers that achieve 2.5 m/s walking speeds with 350 N push recovery on rough terrain.

**Why this priority**: This covers the core locomotion capabilities that enable humanoid robots to navigate effectively in real-world environments.

**Independent Test**: The user can successfully implement the RAISE controller and achieve 2.5 m/s walking speed with 350 N push recovery in both simulation and on real hardware.

**Acceptance Scenarios**:

1. **Given** I am implementing the convex MPC controller, **When** I follow the Chapter 6 instructions, **Then** I achieve 1.9 m/s walking speed with ±8 cm terrain tolerance on Unitree G1
2. **Given** I am training the RAISE controller, **When** I complete the Isaac Lab training process, **Then** I achieve 2.5 m/s walking speed with 350 N push recovery that transfers to real hardware
3. **Given** I am comparing controllers, **When** I run the benchmark tests, **Then** RAISE outperforms all other controllers on the 2025 leaderboard (2.51 m/s, 350 N recovery, ±12 cm terrain tolerance)

---

### User Story 2 - Practitioner Implements Dexterous Manipulation (Priority: P2)

As a robotics practitioner working with dexterous manipulation, I want to access content on hand kinematics, contact modeling, Isaac Lab manipulation environment, and the latest generation of foundation models (RDT-1B, Octo, Diffusion Policy) so that I can achieve 97% success rate on unseen objects with sub-second grasp times.

**Why this priority**: Dexterous manipulation is essential for humanoid robots to interact effectively with their environment and perform complex tasks.

**Independent Test**: The user can successfully deploy the RDT-1B model and achieve 97% success rate on unseen objects with 0.7s grasp time.

**Acceptance Scenarios**:

1. **Given** I am implementing contact modeling with Isaac Lab, **When** I simulate 24 DoF hands, **Then** I achieve 4 kHz physics simulation that runs in real-time
2. **Given** I am using the RDT-1B foundation model, **When** I deploy it for grasping tasks, **Then** I achieve 97% success rate on 1000+ unseen objects with 0.7s average grasp time
3. **Given** I am performing in-hand reorientation, **When** I execute the RDT-1B policy, **Then** I achieve 94% success rate for reorienting objects like pens and hammers

---

### User Story 3 - Instructor Teaches Advanced Locomotion & Manipulation (Priority: P3)

As an instructor teaching advanced locomotion and manipulation techniques, I want to access complete MDX files for Chapters 06-07 with supporting code/assets and _category_.json files so that I can structure my course with reproducible examples and advanced implementation content.

**Why this priority**: Educators need comprehensive resources to teach the latest techniques in humanoid robotics.

**Independent Test**: The instructor can successfully use the complete MDX files and supporting assets to teach advanced locomotion and manipulation concepts.

**Acceptance Scenarios**:

1. **Given** I am teaching locomotion theory, **When** I present the ZMP and Capture Point concepts, **Then** students understand the mathematical foundations of 2025 bipedal control
2. **Given** I am teaching manipulation techniques, **When** I demonstrate the RDT-1B model, **Then** students can implement in-hand reorientation with 90%+ success rate
3. **Given** I am covering whole-body control, **When** I use the QP controller examples, **Then** students can implement controllers that achieve 400 Hz control rates

## Requirements *(mandatory)*

### Functional Requirements

- **FR-001**: All content MUST be in MDX format for Docusaurus compatibility
- **FR-002**: All code examples MUST execute in devcontainer without modification
- **FR-003**: All citations MUST follow IEEE style with minimum 50% peer-reviewed sources
- **FR-004**: Code examples MUST be in Python/ROS 2 as specified
- **FR-005**: Diagrams MUST be created using Mermaid as specified
- **FR-006**: Chapter 6 MUST include complete content on ZMP theory, convex MPC, RL walking SOTA, whole-body QP, RAISE controller, DreamerV3, controller comparison, and full walking demo
- **FR-007**: Chapter 7 MUST include complete content on hand kinematics, contact modeling, Isaac Lab manipulation, diffusion policies, Octo & RDT-1B, in-hand reorientation, grasp synthesis, and full dexterous demo
- **FR-008**: All MDX files MUST contain complete content with proper sidebar positions, titles, and descriptions as specified
- **FR-009**: Supporting code structure MUST match the specified directory structure under src/locomotion/, src/manipulation/, assets/controllers/, and assets/hands/
- **FR-010**: All performance metrics and benchmarks MUST be accurately represented as specified (e.g., 2.5 m/s walking, 350 N push recovery, 97% grasp success)
- **FR-011**: The RAISE controller section MUST include installation, pretrained checkpoints, and Isaac Lab training details
- **FR-012**: The RDT-1B section MUST include installation, inference, and performance benchmarks as specified
- **FR-013**: All chapters MUST include appropriate learning objectives and follow the specified content structure

### Key Entities

- **Chapter**: Organized content unit within the textbook covering specific topics (06-07 in Module 3)
- **Module**: Grouping of related chapters (e.g., Module 3: Locomotion & Dexterous Manipulation)
- **Docusaurus MDX File**: Markdown file with embedded React components for the documentation site
- **Controller**: Algorithm that converts high-level commands to joint torques (e.g., MPC, RAISE, DreamerV3, RDT-1B)
- **Hand Model**: Anthropomorphic end-effector with specified DoF and actuation (Allegro, Shadow, etc.)
- **Foundation Model**: Large-scale neural network trained on robotics data (RDT-1B, Octo, Diffusion Policy)
- **Code Example**: Executable code snippet in Python/ROS 2 that demonstrates concepts

## Success Criteria *(mandatory)*

### Measurable Outcomes

- **SC-001**: Reader can implement the RAISE controller and achieve 2.5 m/s walking with 350 N push recovery
- **SC-002**: Reader can deploy RDT-1B for grasping and achieve 97% success rate on 1000+ unseen objects
- **SC-003**: Reader can execute in-hand reorientation with 90%+ success rate for common objects
- **SC-004**: All code executes in devcontainer without modification
- **SC-005**: All chapters are available in proper MDX format with appropriate metadata
- **SC-006**: Supporting code and assets are correctly placed in the repository
- **SC-007**: All content follows IEEE citation style with minimum 50% peer-reviewed sources
- **SC-008**: All diagrams are created using Mermaid as specified
- **SC-009**: MPC controller achieves 1.9 m/s walking speed with ±8 cm terrain tolerance
- **SC-010**: Isaac Lab can simulate 24+ DoF hands at 4 kHz physics rate
- **SC-011**: Whole-body QP controller runs at 400 Hz solving 36 DoF problems in <2.1 ms
- **SC-012**: In-hand reorientation succeeds >90% for common objects (pen, hammer, bottle cap)