"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook=globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[5943],{4348:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>r,contentTitle:()=>s,default:()=>u,frontMatter:()=>a,metadata:()=>l,toc:()=>c});var i=o(4848),t=o(8453);const a={sidebar_position:1,title:"Chapter 8 \u2013 Vision-Language-Action Models (VLA)",description:"The single biggest leap in robotics since ROS \u2014 now fully open and real-time"},s="Chapter 8: Vision-Language-Action Models (VLA)",l={id:"vla/intro",title:"Chapter 8 \u2013 Vision-Language-Action Models (VLA)",description:"The single biggest leap in robotics since ROS \u2014 now fully open and real-time",source:"@site/docs/08-vla/01-intro.mdx",sourceDirName:"08-vla",slug:"/vla/intro",permalink:"/Physical-AI-Humanoid-Robotics-Textbook/docs/vla/intro",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1,title:"Chapter 8 \u2013 Vision-Language-Action Models (VLA)",description:"The single biggest leap in robotics since ROS \u2014 now fully open and real-time"},sidebar:"tutorialSidebar",previous:{title:"Full Dexterous Demo \u2013 Pick, Reorient, Insert",permalink:"/Physical-AI-Humanoid-Robotics-Textbook/docs/manipulation/full-dexterous-demo"},next:{title:"VLA Landscape \u2013 December 2025 Final Ranking",permalink:"/Physical-AI-Humanoid-Robotics-Textbook/docs/vla/vla-landscape-2025"}},r={},c=[];function d(e){const n={blockquote:"blockquote",h1:"h1",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"chapter-8-vision-language-action-models-vla",children:"Chapter 8: Vision-Language-Action Models (VLA)"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Learning Objectives"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:'Understand why 2024\u20132025 was the "ChatGPT moment" for physical robots'}),"\n",(0,i.jsx)(n.li,{children:"Run OpenVLA, Octo, and RDT-1B locally on a single RTX 4090"}),"\n",(0,i.jsx)(n.li,{children:"Convert any natural language command into a 100 Hz action stream"}),"\n",(0,i.jsx)(n.li,{children:"Build a complete voice\u2192vision\u2192action pipeline that works on real humanoids"}),"\n",(0,i.jsx)(n.li,{children:"Achieve >90 % success on long-horizon, language-conditioned tasks"}),"\n"]}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:'By the end, your humanoid will respond to "Please tidy the table and bring me a red cup" \u2014 exactly like Figure 02.'}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,o)=>{o.d(n,{R:()=>s,x:()=>l});var i=o(6540);const t={},a=i.createContext(t);function s(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);